{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 第1章统计学习方法概论\n",
    "\n",
    "## 习题1.1\n",
    "&emsp;&emsp;说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答思路：**\n",
    "1. 写出伯努利模型；\n",
    "2. 写出伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素；\n",
    "3. 根据伯努利模型的极大似然估计，估计结果为1的概率；\n",
    "4. 根据伯努利模型的贝叶斯估计，估计结果为1的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第1步：伯努利模型**  \n",
    "&emsp;&emsp;根据题意：伯努利模型是定义在取值为0与1的随机变量上的概率分布。  \n",
    "&emsp;&emsp;对于随机变量$X$，则有：\n",
    "$$\n",
    "P(X=1)=p \\\\ P(X=0)=1-p\n",
    "$$\n",
    "\n",
    "其中，$p$为随机变量$X$取值为1的概率，$1-p$则为取0的概率。  \n",
    "&emsp;&emsp;由于随机变量$X$只有0和1两个值，$X$的概率分布函数，即伯努利模型可写为：\n",
    "$$\n",
    "P_p(X=x)=p^x (1-p)^{(1-x)}, \\quad 0 \\leqslant p \\leqslant 1\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;则伯努利模型的假设空间为：\n",
    "$$\n",
    "\\mathcal{F}=\\{P|P_p(X)=p^x(1-p)^{(1-x)}, p\\in [0,1] \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素**  \n",
    "（1）极大似然估计  \n",
    "&emsp;&emsp;模型：伯努利模型  \n",
    "&emsp;&emsp;策略：经验风险最小化。极大似然估计，等价于当模型是条件概率分布、损失函数是对数损失函数时的经验风险最小化。  \n",
    "&emsp;&emsp;算法：极大化似然：$\\displaystyle \\mathop{\\arg\\max} \\limits_{p} L(p|X)= \\mathop{\\arg\\max} \\limits_{p} P(X|p)$ \n",
    "\n",
    "（2）贝叶斯估计  \n",
    "&emsp;&emsp;模型：伯努利模型  \n",
    "&emsp;&emsp;策略：结构风险最小化。贝叶斯估计中的最大后验概率估计，等价于当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时的结构风险最小化。    \n",
    "&emsp;&emsp;算法：最大化后验概率：$\\displaystyle \\mathop{\\arg\\max} \\limits_{p} \\pi (p|X)= \\displaystyle \\mathop{\\arg\\max} \\limits_{p} \\frac{P(X|p)\\pi(p)}{\\int P(X|p)\\pi(p)dp}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第3步：伯努利模型的极大似然估计**  \n",
    "\n",
    "&emsp;&emsp;极大似然估计的一般步骤：  \n",
    "&emsp;&emsp;参考Wiki：https://en.wikipedia.org/wiki/Maximum_likelihood_estimation  \n",
    "> 1. 写出随机变量的概率分布函数；  \n",
    "> 2. 写出似然函数；  \n",
    "> 3. 对似然函数取对数，得到对数似然函数，并进行化简；  \n",
    "> 4. 对参数进行求导，并令导数等于0；  \n",
    "> 5. 求解似然函数方程，得到参数的值。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，可得似然函数为：\n",
    "$$\n",
    "\\begin{aligned} L(p|X) &= P(X|p) \\\\\n",
    "&= \\prod_{i=1}^{n} P(x^{(i)}|p) \\\\\n",
    "&=p^k (1-p)^{n-k}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对似然函数取对数，得到对数似然函数为：\n",
    "$$\n",
    "\\begin{aligned} \\log L(p|X) &= \\log p^k (1-p)^{n-k} \\\\\n",
    "&= \\log(p^k) + \\log\\left( (1-p)^{n-k} \\right) \\\\\n",
    "&= k\\log p + (n-k)\\log (1-p)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;求解参数$p$：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{p} &= \\mathop{\\arg\\max} \\limits_{p} L(p|X) \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{p} \\left[ k\\log p + (n-k)\\log (1-p) \\right]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对参数$p$求导，并求解导数为0时的$p$值：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\log L(p)}{\\partial p} &= \\frac{k}{p} - \\frac{n-k}{1-p} \\\\\n",
    "&= \\frac{k(1-p) - p(n-k)}{p(1-p)} \\\\\n",
    "&= \\frac{k-np}{p(1-p)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;令$\\displaystyle \\frac{\\partial \\log L(p)}{\\partial p} = 0$，从上式可得，$k-np=0$，即$\\displaystyle p=\\frac{k}{n}$  \n",
    "&emsp;&emsp;所以$\\displaystyle P(X=1)=\\frac{k}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第4步：伯努利模型的贝叶斯估计**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解法一：求最大后验估计\n",
    "\n",
    "&emsp;&emsp;贝叶斯估计（最大后验估计）的一般步骤：  \n",
    "&emsp;&emsp;参考Wiki：https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n",
    "> 1. 确定参数$\\theta$的先验概率$p(\\theta)$  \n",
    "> 2. 根据样本集$D=\\{ x_1, x_2, \\ldots, x_n \\}$，计算似然函数$P(D|\\theta)$：$\\displaystyle P(D|\\theta)=\\prod_{i=1}^n P(x_i|D)$  \n",
    "> 3. 利用贝叶斯公式，写出后验概率最大化公式：  \n",
    "> $$\n",
    "\\mathop{\\arg\\max} \\limits_{\\theta}  P(\\theta|D)=\\mathop{\\arg\\max} \\limits_{\\theta} \\frac{P(D|\\theta)P(\\theta)}{\\displaystyle \\int \\limits_\\Theta P(D|\\theta) P(\\theta) d \\theta} = \\mathop{\\arg\\max} \\limits_{\\theta} P(D|\\theta)P(\\theta)\n",
    "$$ \n",
    "> 4. 利用求导，得到后验概率最大时的参数取值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于伯努利模型的参数$p$，根据贝叶斯估计，该参数也是随机变量。  \n",
    "&emsp;&emsp;假设$p$的先验分布$\\pi(p)$为均匀分布，则最大后验概率估计等价于极大似然估计。  \n",
    "&emsp;&emsp;一般在贝叶斯估计中，如果后验分布与先验分布属于同一分布簇（共轭分布），则称此先验分布为似然函数的共轭先验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;参考[极大似然估计和贝叶斯估计](https://zhuanlan.zhihu.com/p/61593112)\n",
    "> 选取共轭先验有如下好处，例如：    \n",
    ">（1）符合直观，先验分布和后验分布应该是相同形式的；  \n",
    ">（2）可以给出后验分布的解析形式；  \n",
    ">（3）可以形成一个先验链，即现在的后验分布可以作为下一次计算的先验分布，如果形式相同，就可以形成一个链条。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;伯努利分布的先验分布为Beta分布，则此处假设先验分布$\\pi(p)$为Beta分布。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **补充知识：Beta分布**  \n",
    "> 来源维基百科：https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83     \n",
    "&emsp;&emsp;Beta 分布（Beta distribution），是指一组定义在${\\displaystyle (0,1)}$区间的连续概率分布，亦称Β分布。有两个参数$\\alpha, \\beta>0$。  \n",
    "> 概率密度函数：$\\displaystyle f(x; \\alpha, \\beta)= \\frac{1}{{\\rm B}(\\alpha, \\beta)}x^{(\\alpha-1)}(1-x)^{\\beta-1}$   \n",
    "其中${\\rm B}(\\alpha, \\beta)$是Beta函数，亦称Β函数。$\\displaystyle {\\rm B}(\\alpha, \\beta) =\\int _{0}^{1} x^{\\alpha-1}(1-x)^{\\beta-1}dx$   \n",
    "> 随机变量$X$服从参数为$\\alpha, \\beta$的Beta分布记作：$X \\sim {\\rm Be}(\\alpha, \\beta)$   \n",
    "> 期望：$\\displaystyle {\\rm E}(X) = \\frac{\\alpha}{\\alpha+\\beta}$   \n",
    "> 与均匀分布关系：当$\\alpha=1, \\beta=1$时，Beta分布就是一个均匀分布  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;$p$的先验分布为：  \n",
    "$$\n",
    "\\displaystyle \\pi (p) = \\frac{1}{B(\\alpha, \\beta)} p^{(\\alpha-1)} (1-p)^{\\beta-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;似然函数与第3步相同：\n",
    "$$\n",
    "\\begin{aligned} L(p|X) &= P(X|p) \\\\\n",
    "&= \\prod_{i=1}^{n} P(x^{(i)}|p) \\\\\n",
    "&=p^k (1-p)^{n-k}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最大化后验概率，求解参数$p$：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{p} &= \\mathop{\\arg\\max} \\limits_{p} \\frac{P(X|p)\\pi(p)}{\\displaystyle \\int P(X|p)\\pi(p)dp} \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{p} P(X|p)\\pi(p) \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{p} p^k (1-p)^{n-k} \\frac{1}{B(\\alpha, \\beta)} p^{(\\alpha-1)} (1-p)^{\\beta-1} \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{p} \\frac{1}{B(\\alpha, \\beta)} p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;令$\\displaystyle g(p) = \\frac{1}{B(\\alpha, \\beta)} p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1}$，对函数$g(p)$先取对数，再对$p$求导，得\n",
    "$$ \\frac{\\partial \\log g(p)}{\\partial p} = \\frac{1}{B(\\alpha, \\beta)} \\left( \\frac{k+\\alpha-1}{p} - \\frac{n-k+\\beta-1}{1-p} \\right)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;令上式等于0，得$\\displaystyle \\hat{p} = \\frac{k+\\alpha-1}{n+\\alpha+\\beta-2}$，其中$\\alpha, \\beta$为beta分布的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所以最大后验概率估计得到$\\displaystyle P(X=1)=\\frac{k+\\alpha-1}{n+\\alpha+\\beta-2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解法二：求后验概率分布的期望  \n",
    "\n",
    "&emsp;&emsp;后验概率分布的期望求解  \n",
    "&emsp;&emsp;参考Wiki（中文）：https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87  \n",
    "&emsp;&emsp;参考Wiki（英文）：https://en.wikipedia.org/wiki/Bayes_estimator  \n",
    "> &emsp;&emsp;贝叶斯估计中的最大后验概率估计，得到的是模型参数$\\theta$这个随机变量的后验分布的众数，通常被认为是点估计。而贝叶斯方法的特点是使用分布来总结数据和得出推论，因此贝叶斯方法倾向于得到后验均值或中值，以及可信区间。  \n",
    "> &emsp;&emsp;贝叶斯估计，利用后验分布的期望（均值）作为参数的估计值的方法，前两步与最大后验概率估计相同，第3、4步如下：  \n",
    "> 3. 利用贝叶斯公式，求$\\theta$的后验概率：$\\displaystyle P(\\theta|D)=\\frac{P(D|\\theta)P(\\theta)}{\\displaystyle \\int \\limits_\\Theta P(D|\\theta) P(\\theta) d \\theta}$   \n",
    "> 4. 计算后验概率分布参数$\\theta$的期望，并求出贝叶斯估计值：$\\displaystyle \\hat{\\theta}=\\int \\limits_{\\Theta} \\theta \\cdot P(\\theta|D) d \\theta$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;已知似然函数和参数$p$的先验分布，参数$p$的后验分布为：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(p|X) &= \\frac{P(X|p)\\pi(p)}{\\displaystyle \\int P(X|p)\\pi(p)dp} \\\\\n",
    "&=\\frac{\\displaystyle  \\frac{1}{B(\\alpha, \\beta)}  p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1}}{\\displaystyle  \\int \\frac{1}{B(\\alpha, \\beta)}  p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1} dp} \\\\\n",
    "&=\\frac{ p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1}}{\\displaystyle \\int p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1} dp} \\\\\n",
    "&=\\frac{1}{B(k+\\alpha, n-k+\\beta)} p^{k+\\alpha-1} (1-p)^{n-k+\\beta-1} \\\\\n",
    "&\\sim \\text{Be}(k+\\alpha, n-k+\\beta) \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;后验概率分布的期望:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E_p(p|X)&=E_p({\\rm Be}(k+\\alpha, n-k+\\beta)) \\\\\n",
    "&=\\frac{k+\\alpha}{(k+\\alpha)+(n-k+\\beta)} \\\\\n",
    "&=\\frac{k+\\alpha}{n+\\alpha+\\beta}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;则以参数的后验概率分布的期望作为贝叶斯估计的参数值：\n",
    "$$\n",
    "\\displaystyle \\hat{p}=\\frac{k+\\alpha}{n+\\alpha+\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所以贝叶斯估计得到$\\displaystyle P(X=1)=\\frac{k+\\alpha}{n+\\alpha+\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题1.2\n",
    "&emsp;&emsp;通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**\n",
    "\n",
    "**解答思路：**  \n",
    "1. 根据经验风险最小化定义，写出目标函数；\n",
    "2. 根据对数损失函数，对目标函数进行整理；\n",
    "3. 根据似然函数定义和极大似然估计的一般步骤（计算时需要取对数），可得到结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**  \n",
    "&emsp;&emsp;假设模型的条件概率分布是$P_{\\theta}(Y|X)$，样本集$D=\\{(x_1,y_1),(x_2,y_2),\\ldots,(x_N,y_N)\\}$，根据书中第17页公式(1.12)，对数损失函数为：  \n",
    "$$\n",
    "L(Y,P(Y|X)) = -\\log P(Y|X)\n",
    "$$\n",
    "&emsp;&emsp;根据书中第18页公式(1.15)，按照经验风险最小化求最优模型就是求解最优化问题：  \n",
    "$$\n",
    "\\min \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^N L(y_i, f(x_i))\n",
    "$$\n",
    "&emsp;&emsp;结合上述两个式子，可得经验风险最小化函数：  \n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\mathop{\\arg\\min} \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^N L(y_i, f(x_i)) &= \\mathop{\\arg\\min} \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_D [-\\log P(Y|X)] \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_D \\log P(Y|X) \\\\\n",
    "&= \\mathop{\\arg\\max} \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\log \\prod_D P(Y|X) \\\\\n",
    "&= \\frac{1}{N} \\mathop{\\arg\\max} \\limits_{f \\in \\mathcal{F}} \\log \\prod_D P(Y|X)\n",
    "\\end{aligned}\n",
    "$$\n",
    "&emsp;&emsp;根据似然函数定义：$\\displaystyle L(\\theta)=\\prod_D P_{\\theta}(Y|X)$，以及极大似然估计的一般步骤，可得：  \n",
    "$$\n",
    "\\mathop{\\arg\\min} \\limits_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^N L(y_i, f(x_i)) = \\frac{1}{N} \\mathop{\\arg\\max} \\limits_{f \\in \\mathcal{F}} \\log L(\\theta)\n",
    "$$\n",
    "&emsp;&emsp;即经验风险最小化等价于极大似然估计，得证。  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c50c7698ff25eb1d7dce4c52e3d5cc14b3b23d6a97d4fb70aad8c815eba6f63e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
